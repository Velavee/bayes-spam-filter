{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed19cfc7",
   "metadata": {},
   "source": [
    "# Bayes Theorem for Predicting the Probability of an Email Being Spam\n",
    "\n",
    "S = Spam\n",
    "w = Word\n",
    "\n",
    "$P(Spam|w_{1}, w_{2},..., w_{n}) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_{i}|Spam)$\n",
    "\n",
    "The probability that an email consisting of the words $w_{1}, w_{2},... w_{n}$ is proportional to the probability that any given email is spam multiplied by the product of each word's probability to appear in a spam email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f68506f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "PREDICTION = 'Prediction'\n",
    "CLASSIFICATION = 'Classiciation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c127b8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81159678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocab(emails):\n",
    "    total_words = 0\n",
    "    \n",
    "    for index, row in emails.iterrows():\n",
    "        total_words += sum(row.values[1:-2])\n",
    "            \n",
    "    return total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8521603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_spamicity(w_spam_count, vocab, spam_vocab):\n",
    "    alpha = 1\n",
    "    \n",
    "    spamicity = (w_spam_count + alpha) / (spam_vocab + alpha * vocab)\n",
    "    return spamicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2558e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_spamicity_dict(spam_emails, vocab, spam_vocab):\n",
    "    spam_word_appearances = {}\n",
    "    \n",
    "    for (column_name, column_data) in spam_emails.iteritems():\n",
    "        if column_name != 'Email No.' and column_name != PREDICTION and column_name != CLASSIFICATION:\n",
    "            spam_word_appearances[column_name] = sum(column_data.values)\n",
    "            \n",
    "    for word in spam_word_appearances:\n",
    "        spam_word_appearances[word] = calculate_word_spamicity(spam_word_appearances[word], vocab, spam_vocab)\n",
    "            \n",
    "    return spam_word_appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0da3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_email(email, word_spamicities, word_hamicities, spam_proportion, ham_proportion, testing_data):\n",
    "    email_spamicity = math.log(spam_proportion)\n",
    "    email_hamicity = math.log(ham_proportion)\n",
    "    \n",
    "    for column in testing_data.columns[1:-2]:\n",
    "        if email[column] > 0:\n",
    "            email_spamicity += math.log(word_spamicities[column])*email[column]\n",
    "            email_hamicity += math.log(word_hamicities[column])*email[column]\n",
    "            \n",
    "    return 1 if email_spamicity >= email_hamicity else 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27112486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(testing_emails):\n",
    "    number_correct = 0\n",
    "    for index, email in testing_emails.iterrows():\n",
    "        if email[PREDICTION] == email[CLASSIFICATION]:\n",
    "            number_correct += 1\n",
    "        \n",
    "    return number_correct / testing_emails.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "678dbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data, include_stop_words=True):\n",
    "    if include_stop_words:\n",
    "        # Take out all stopwords\n",
    "        for col in df.columns:\n",
    "            if col in stop_words:\n",
    "                data.drop(col, axis=1, inplace=True)\n",
    "                \n",
    "    results = {'Accuracy': [], 'Time Elapsed': []}\n",
    "\n",
    "    total_num_emails = data.shape[0]\n",
    "    print(f'Total # Emails:{total_num_emails}')\n",
    "\n",
    "    # Subtract 2 for \"Email No.\" and \"Prediction\" columns\n",
    "    total_vocab = len(data.columns) - 2\n",
    "    print(f'Total Vocab: {total_vocab}')\n",
    "\n",
    "    partition_size = total_num_emails//5\n",
    "\n",
    "    end = 0\n",
    "    begin = 0\n",
    "    score_total = 0\n",
    "    time_total = 0\n",
    "\n",
    "\n",
    "    for i in range(1,6):\n",
    "        start_time = time.time()\n",
    "        end += partition_size\n",
    "\n",
    "        if i == 5:\n",
    "            testing_data = data.iloc[begin:].copy()\n",
    "        else:\n",
    "            testing_data = data.iloc[begin:end].copy()\n",
    "\n",
    "        # This is where the model's prediction will be stored\n",
    "        testing_data[CLASSIFICATION] = \"\"\n",
    "\n",
    "        if i == 1:\n",
    "            training_data = df.iloc[end:]\n",
    "        elif i == 5:\n",
    "            training_data = df.iloc[:begin]\n",
    "        else:\n",
    "            training_data_sections = []\n",
    "            training_data_sections.append(data.iloc[:begin])\n",
    "            training_data_sections.append(data.iloc[end:])\n",
    "            training_data = pd.concat(training_data_sections)\n",
    "\n",
    "        begin += partition_size\n",
    "        print(f'\\nBegin: {testing_data.at[testing_data.index[0],\"Email No.\"]}')\n",
    "        print(f'End: {testing_data.at[testing_data.index[-1],\"Email No.\"]}')\n",
    "\n",
    "        spam_proportion = training_data['Prediction'].value_counts()[1] / training_data.shape[0]\n",
    "        print(f'% of spam emails: {spam_proportion}')\n",
    "\n",
    "        ham_proportion = training_data['Prediction'].value_counts()[0] / training_data.shape[0]\n",
    "        print(f'% of ham emails: {ham_proportion}')\n",
    "\n",
    "        spam_training_emails = training_data.loc[training_data[PREDICTION] == 1]\n",
    "\n",
    "        total_spam_words = count_vocab(spam_training_emails)\n",
    "        print(f'total spam words: {total_spam_words}')\n",
    "\n",
    "        ham_training_emails = training_data.loc[training_data[PREDICTION] == 0]\n",
    "\n",
    "        total_ham_words = count_vocab(ham_training_emails)\n",
    "        print(f'total ham words: {total_ham_words}')\n",
    "\n",
    "        word_spamicities = build_word_spamicity_dict(spam_training_emails, total_vocab, total_spam_words)\n",
    "        word_hamicities = build_word_spamicity_dict(ham_training_emails, total_vocab, total_ham_words)\n",
    "\n",
    "        i = 0\n",
    "        for index, email in testing_data.iterrows():\n",
    "            testing_data[CLASSIFICATION].loc[testing_data.index[i]] = calculate_email(email, word_spamicities, word_hamicities, spam_proportion, ham_proportion, testing_data)\n",
    "            i += 1\n",
    "\n",
    "        score = calculate_accuracy(testing_data)\n",
    "        print(f'Accuracy: {score}%')\n",
    "        results['Accuracy'].append(score)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f'Time Elapsed: {elapsed_time}')\n",
    "        results['Time Elapsed'].append(elapsed_time)\n",
    "        \n",
    "        score_total += score\n",
    "        time_total += elapsed_time\n",
    "\n",
    "    print(f'\\nAverage Accuracy: {score_total/5}%')\n",
    "    print(f'Average Time: {time_total/5}%')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83be745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42190751",
   "metadata": {},
   "source": [
    "## Step 1: Partition the data into training and test segments\n",
    "\n",
    "20% of the data for testing, and the remaining 80% is training (i.e. the 80% training data will confirm whether the 20% testing data labels are correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9645163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS INCLUDED\n",
      "\n",
      "Total # Emails:5172\n",
      "Total Vocab: 3000\n",
      "\n",
      "Begin: Email 1\n",
      "End: Email 1034\n",
      "% of spam emails: 0.291445142580957\n",
      "% of ham emails: 0.708554857419043\n",
      "total spam words: 1708339\n",
      "total ham words: 2972320\n",
      "Accuracy: 93.90715667311412%\n",
      "Time Elapsed: 11.311661005020142\n",
      "\n",
      "Begin: Email 1035\n",
      "End: Email 2068\n",
      "% of spam emails: 0.29337844369260513\n",
      "% of ham emails: 0.7066215563073949\n",
      "total spam words: 1757177\n",
      "total ham words: 3079137\n",
      "Accuracy: 96.5183752417795%\n",
      "Time Elapsed: 11.190126895904541\n",
      "\n",
      "Begin: Email 2069\n",
      "End: Email 3102\n",
      "% of spam emails: 0.291686805219913\n",
      "% of ham emails: 0.708313194780087\n",
      "total spam words: 1893092\n",
      "total ham words: 3181821\n",
      "Accuracy: 95.45454545454545%\n",
      "Time Elapsed: 11.121826171875\n",
      "\n",
      "Begin: Email 3103\n",
      "End: Email 4136\n",
      "% of spam emails: 0.28709521507974867\n",
      "% of ham emails: 0.7129047849202513\n",
      "total spam words: 1695443\n",
      "total ham words: 3219402\n",
      "Accuracy: 93.81044487427465%\n",
      "Time Elapsed: 11.344186067581177\n",
      "\n",
      "Begin: Email 4137\n",
      "End: Email 5172\n",
      "% of spam emails: 0.28650870406189555\n",
      "% of ham emails: 0.7134912959381045\n",
      "total spam words: 1698705\n",
      "total ham words: 2901928\n",
      "Accuracy: 90.63706563706563%\n",
      "Time Elapsed: 11.47169303894043\n",
      "\n",
      "Average Accuracy: 94.06551757615587%\n",
      "Average Time: 11.287898635864257%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.907157</td>\n",
       "      <td>11.311661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.518375</td>\n",
       "      <td>11.190127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.454545</td>\n",
       "      <td>11.121826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.810445</td>\n",
       "      <td>11.344186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.637066</td>\n",
       "      <td>11.471693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Time Elapsed\n",
       "0  93.907157     11.311661\n",
       "1  96.518375     11.190127\n",
       "2  95.454545     11.121826\n",
       "3  93.810445     11.344186\n",
       "4  90.637066     11.471693"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "\n",
    "print('STOP WORDS INCLUDED\\n')\n",
    "with_stopwords_results = run_model(df, False)\n",
    "pd.DataFrame(data = with_stopwords_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78f99e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS NOT INCLUDED\n",
      "\n",
      "Total # Emails:5172\n",
      "Total Vocab: 3000\n",
      "\n",
      "Begin: Email 1\n",
      "End: Email 1034\n",
      "% of spam emails: 0.291445142580957\n",
      "% of ham emails: 0.708554857419043\n",
      "total spam words: 1708339\n",
      "total ham words: 2972320\n",
      "Accuracy: 93.90715667311412%\n",
      "Time Elapsed: 11.457571029663086\n",
      "\n",
      "Begin: Email 1035\n",
      "End: Email 2068\n",
      "% of spam emails: 0.29337844369260513\n",
      "% of ham emails: 0.7066215563073949\n",
      "total spam words: 1757177\n",
      "total ham words: 3079137\n",
      "Accuracy: 96.5183752417795%\n",
      "Time Elapsed: 11.33948802947998\n",
      "\n",
      "Begin: Email 2069\n",
      "End: Email 3102\n",
      "% of spam emails: 0.291686805219913\n",
      "% of ham emails: 0.708313194780087\n",
      "total spam words: 1893092\n",
      "total ham words: 3181821\n",
      "Accuracy: 95.45454545454545%\n",
      "Time Elapsed: 11.206914186477661\n",
      "\n",
      "Begin: Email 3103\n",
      "End: Email 4136\n",
      "% of spam emails: 0.28709521507974867\n",
      "% of ham emails: 0.7129047849202513\n",
      "total spam words: 1695443\n",
      "total ham words: 3219402\n",
      "Accuracy: 93.81044487427465%\n",
      "Time Elapsed: 11.290531158447266\n",
      "\n",
      "Begin: Email 4137\n",
      "End: Email 5172\n",
      "% of spam emails: 0.28650870406189555\n",
      "% of ham emails: 0.7134912959381045\n",
      "total spam words: 1698705\n",
      "total ham words: 2901928\n",
      "Accuracy: 90.63706563706563%\n",
      "Time Elapsed: 11.501758813858032\n",
      "\n",
      "Average Accuracy: 94.06551757615587%\n",
      "Average Time: 11.359252643585204%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Partition 1</th>\n",
       "      <td>93.907157</td>\n",
       "      <td>11.457571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partition 2</th>\n",
       "      <td>96.518375</td>\n",
       "      <td>11.339488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partition 3</th>\n",
       "      <td>95.454545</td>\n",
       "      <td>11.206914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partition 4</th>\n",
       "      <td>93.810445</td>\n",
       "      <td>11.290531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partition 5</th>\n",
       "      <td>90.637066</td>\n",
       "      <td>11.501759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy  Time Elapsed\n",
       "Partition 1  93.907157     11.457571\n",
       "Partition 2  96.518375     11.339488\n",
       "Partition 3  95.454545     11.206914\n",
       "Partition 4  93.810445     11.290531\n",
       "Partition 5  90.637066     11.501759"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('STOP WORDS NOT INCLUDED\\n')\n",
    "without_stopwords_results = run_model(df, False)\n",
    "stored_results = pd.DataFrame(data = without_stopwords_results)\n",
    "stored_results.index = ['Partition 1', 'Partition 2', 'Partition 3', 'Partition 4', 'Partition 5']\n",
    "stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e254a",
   "metadata": {},
   "source": [
    "## Step 2: Get probabilities that any one email in the training data is either spam or ham\n",
    "\n",
    "In the labelled dataset, count the number of spam and ham emails.\n",
    "\n",
    "$P(Spam) = \\frac{Spam\\,Emails}{Total\\,Emails}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bca9ca",
   "metadata": {},
   "source": [
    "$P(Ham) = \\frac{Ham\\,Emails}{Total\\,Emails}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e43c9",
   "metadata": {},
   "source": [
    "## Step 3: Get the \"spamicity\" and \"hamicity\" probability of each word in the testing data email\n",
    "\n",
    "**w** = word\n",
    "<br>**vocab** = total words in dataset\n",
    "<br>**spam_vocab**\n",
    "<br>**wi_spam_count**\n",
    "\n",
    "Count all unique words in the labelled dataset to get **vocab**.\n",
    "\n",
    "Count the total number of words in labelled spam emails (ignoring uniqueness) to get **spam_vocab**.\n",
    "\n",
    "For each word **w**, count all instances of the word in the spam emails to get **wi_spam_count**.\n",
    "\n",
    "Calculate spamicity of each word and store the word and its spamicity in a dictionary\n",
    "\n",
    "$P(w_{i}|Spam) = \\frac{wi\\_spam\\_count\\,+\\,\\alpha}{spam\\_vocab\\,+\\,\\alpha \\cdot vocab}$\n",
    "\n",
    "$\\alpha$ is a coefficient that prevents a probability from being 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba26950",
   "metadata": {},
   "source": [
    "## Step 4: Calculate the \"spamicity\" and \"hamicity\" of each email\n",
    "\n",
    "Multiply spamicities of each word together to get $\\prod_{i=1}^{n}P(w_{i}|Spam)$.\n",
    "\n",
    "Multiply that product by the probability that any email is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98189d84",
   "metadata": {},
   "source": [
    "## Step 5: Compare hamicity and spamicity scores to classify emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728084db",
   "metadata": {},
   "source": [
    "## Step 6: Check accuracy of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
