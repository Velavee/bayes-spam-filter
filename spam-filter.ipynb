{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed19cfc7",
   "metadata": {},
   "source": [
    "# Bayes Theorem for Predicting the Probability of an Email Being Spam\n",
    "\n",
    "S = Spam\n",
    "w = Word\n",
    "\n",
    "$P(Spam|w_{1}, w_{2},..., w_{n}) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_{i}|Spam)$\n",
    "\n",
    "The probability that an email consisting of the words $w_{1}, w_{2},... w_{n}$ is proportional to the probability that any given email is spam multiplied by the product of each word's probability to appear in a spam email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68506f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "PREDICTION = 'Prediction'\n",
    "CLASSIFICATION = 'Classiciation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c127b8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e16d35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_Model:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.time_accuracy_results = {'partition': [], 'accuracy': [], 'time_elapsed': []}\n",
    "        self.confusion_matrix = {\n",
    "           'email_#': list(range(1,self.data.shape[0]+1)),\n",
    "           'actual_classification': data[PREDICTION].values.tolist(),\n",
    "           'predicted_classification': [],\n",
    "           'result': []\n",
    "          }\n",
    "        \n",
    "    def consolidate_training_data(self, begin, end, i):\n",
    "        if i == 1:\n",
    "                training_data = self.data.iloc[end:]\n",
    "        elif i == 5:\n",
    "            training_data = self.data.iloc[:begin]\n",
    "        else:\n",
    "            training_data_sections = []\n",
    "            training_data_sections.append(self.data.iloc[:begin])\n",
    "            training_data_sections.append(self.data.iloc[end:])\n",
    "            training_data = pd.concat(training_data_sections)\n",
    "            \n",
    "        return training_data\n",
    "    \n",
    "    def count_vocab(self, emails):\n",
    "        total_words = 0\n",
    "\n",
    "        for index, row in emails.iterrows():\n",
    "            total_words += sum(row.values[1:-2])\n",
    "\n",
    "        return total_words\n",
    "    \n",
    "    def calculate_word_spamicity(self, w_spam_count, vocab, spam_vocab):\n",
    "        alpha = 1\n",
    "\n",
    "        spamicity = (w_spam_count + alpha) / (spam_vocab + alpha * vocab)\n",
    "        return spamicity\n",
    "    \n",
    "    def build_word_spamicity_dict(self, spam_emails, vocab, spam_vocab):\n",
    "        spam_word_appearances = {}\n",
    "\n",
    "        for (column_name, column_data) in spam_emails.iteritems():\n",
    "            if column_name != 'Email No.' and column_name != PREDICTION and column_name != CLASSIFICATION:\n",
    "                spam_word_appearances[column_name] = sum(column_data.values)\n",
    "\n",
    "        for word in spam_word_appearances:\n",
    "            spam_word_appearances[word] = self.calculate_word_spamicity(spam_word_appearances[word], vocab, spam_vocab)\n",
    "\n",
    "        return spam_word_appearances\n",
    "    \n",
    "    def calculate_email(self, email, word_spamicities, word_hamicities, spam_proportion, ham_proportion, testing_data):\n",
    "        email_spamicity = math.log(spam_proportion)\n",
    "        email_hamicity = math.log(ham_proportion)\n",
    "\n",
    "        for column in testing_data.columns[1:-2]:\n",
    "            if email[column] > 0:\n",
    "                email_spamicity += math.log(word_spamicities[column])*email[column]\n",
    "                email_hamicity += math.log(word_hamicities[column])*email[column]\n",
    "\n",
    "        return 1 if email_spamicity >= email_hamicity else 0\n",
    "    \n",
    "    def calculate_accuracy(self, testing_emails):\n",
    "        number_correct = 0\n",
    "        for index, email in testing_emails.iterrows():\n",
    "            if email[PREDICTION] == email[CLASSIFICATION]:\n",
    "                number_correct += 1\n",
    "\n",
    "        return number_correct / testing_emails.shape[0] * 100\n",
    "    \n",
    "    def build_confusion_matrix(self):\n",
    "        print(len(self.confusion_matrix['predicted_classification']))\n",
    "        print(len(self.confusion_matrix['actual_classification']))\n",
    "        for i in range(len(self.confusion_matrix['email_#'])):\n",
    "            actual = self.confusion_matrix['predicted_classification'][i]\n",
    "            predicted = self.confusion_matrix['actual_classification'][i]\n",
    "            \n",
    "            \n",
    "            if actual and predicted:\n",
    "                self.confusion_matrix['result'].append('TP')\n",
    "            elif not actual and not predicted:\n",
    "                self.confusion_matrix['result'].append('TN')\n",
    "            elif actual and not predicted:\n",
    "                self.confusion_matrix['result'].append('FN')\n",
    "            else:\n",
    "                self.confusion_matrix['result'].append('FP')\n",
    "    \n",
    "    def run_partitions(self, include_stop_words=True):\n",
    "        end = 0\n",
    "        begin = 0\n",
    "        total_num_emails = self.data.shape[0]\n",
    "        partition_size = total_num_emails//5\n",
    "        self.data[CLASSIFICATION] = \"\"\n",
    "        \n",
    "        # Subtract 2 for \"Email No.\" and \"Prediction\" columns\n",
    "        total_vocab = len(self.data.columns) - 2\n",
    "        \n",
    "        if not include_stop_words:\n",
    "            # Take out all stopwords\n",
    "            for col in df.columns:\n",
    "                if col in stop_words:\n",
    "                    self.data.drop(col, axis=1, inplace=True)\n",
    "                    \n",
    "        for i in range(1,6):\n",
    "            self.time_accuracy_results['partition'].append(i)\n",
    "            start_time = time.time()\n",
    "            end += partition_size\n",
    "            \n",
    "            if i != 5:\n",
    "                testing_data = self.data.iloc[begin:end]\n",
    "            else:\n",
    "                testing_data = self.data.iloc[begin:]\n",
    "            \n",
    "            print(f'Partition {i}')\n",
    "            print(begin)\n",
    "            print(end)\n",
    "\n",
    "            training_data = self.consolidate_training_data(begin, end, i)\n",
    "            \n",
    "            begin += partition_size\n",
    "\n",
    "            spam_proportion = training_data[PREDICTION].value_counts()[1] / training_data.shape[0]\n",
    "            ham_proportion = training_data[PREDICTION].value_counts()[0] / training_data.shape[0]\n",
    "\n",
    "            spam_training_emails = training_data.loc[training_data[PREDICTION] == 1]\n",
    "            total_spam_words = self.count_vocab(spam_training_emails)\n",
    "\n",
    "            ham_training_emails = training_data.loc[training_data[PREDICTION] == 0]\n",
    "            total_ham_words = self.count_vocab(ham_training_emails)\n",
    "\n",
    "            word_spamicities = self.build_word_spamicity_dict(spam_training_emails, total_vocab, total_spam_words)\n",
    "            word_hamicities = self.build_word_spamicity_dict(ham_training_emails, total_vocab, total_ham_words)\n",
    "            \n",
    "            j = 0\n",
    "            for index, email in testing_data.iterrows():\n",
    "                result = self.calculate_email(email, word_spamicities, word_hamicities, spam_proportion, ham_proportion, testing_data)\n",
    "                testing_data[CLASSIFICATION].loc[testing_data.index[j]] = result\n",
    "                self.confusion_matrix[\"predicted_classification\"].append(result)\n",
    "                j += 1\n",
    "                \n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            self.time_accuracy_results['time_elapsed'].append(elapsed_time)\n",
    "                \n",
    "            score = self.calculate_accuracy(testing_data)\n",
    "            self.time_accuracy_results['accuracy'].append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83be745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42190751",
   "metadata": {},
   "source": [
    "## Step 1: Partition the data into training and test segments\n",
    "\n",
    "20% of the data for testing, and the remaining 80% is training (i.e. the 80% training data will confirm whether the 20% testing data labels are correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c84227af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS INCLUDED\n",
      "Partition 1\n",
      "0\n",
      "1034\n",
      "Partition 2\n",
      "1034\n",
      "2068\n",
      "Partition 3\n",
      "2068\n",
      "3102\n",
      "Partition 4\n",
      "3102\n",
      "4136\n",
      "Partition 5\n",
      "4136\n",
      "5170\n",
      "{'partition': [1, 2, 3, 4, 5], 'accuracy': [93.90715667311412, 96.5183752417795, 95.45454545454545, 93.81044487427465, 90.63706563706563], 'time_elapsed': [11.271054983139038, 11.186248064041138, 11.31614875793457, 11.225033044815063, 11.405194997787476]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>93.907157</td>\n",
       "      <td>11.271055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>96.518375</td>\n",
       "      <td>11.186248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>95.454545</td>\n",
       "      <td>11.316149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>93.810445</td>\n",
       "      <td>11.225033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>90.637066</td>\n",
       "      <td>11.405195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   partition   accuracy  time_elapsed\n",
       "0          1  93.907157     11.271055\n",
       "1          2  96.518375     11.186248\n",
       "2          3  95.454545     11.316149\n",
       "3          4  93.810445     11.225033\n",
       "4          5  90.637066     11.405195"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "\n",
    "nb_with_stopwords = NB_Model(df)\n",
    "\n",
    "print('STOP WORDS INCLUDED')\n",
    "nb_with_stopwords.run_partitions(True)\n",
    "print(nb_with_stopwords.time_accuracy_results)\n",
    "with_stopwords_table = pd.DataFrame(data = nb_with_stopwords.time_accuracy_results)\n",
    "with_stopwords_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e3715e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n",
      "5172\n",
      "5172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_#</th>\n",
       "      <th>actual_classification</th>\n",
       "      <th>predicted_classification</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>5168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>5169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>5170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>5171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>5172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      email_#  actual_classification  predicted_classification result\n",
       "0           1                      0                         0     TN\n",
       "1           2                      0                         0     TN\n",
       "2           3                      0                         0     TN\n",
       "3           4                      0                         0     TN\n",
       "4           5                      0                         0     TN\n",
       "...       ...                    ...                       ...    ...\n",
       "5167     5168                      0                         0     TN\n",
       "5168     5169                      0                         0     TN\n",
       "5169     5170                      1                         1     TP\n",
       "5170     5171                      1                         1     TP\n",
       "5171     5172                      0                         0     TN\n",
       "\n",
       "[5172 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_with_stopwords.build_confusion_matrix()\n",
    "print(len(nb_with_stopwords.confusion_matrix['result']))\n",
    "pd.DataFrame(data=nb_with_stopwords.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_wo_stopwords = NB_Model(df)\n",
    "\n",
    "print('STOP WORDS NOT INCLUDED')\n",
    "nb_wo_stopwords.run_partitions(False)\n",
    "without_stopwords_table = pd.DataFrame(data = nb_wo_stopwords.time_accuracy_results)\n",
    "without_stopwords_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_stopwords_table['with_stopwords'] = [True]*with_stopwords_table.shape[0]\n",
    "with_stopwords_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe8255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "without_stopwords_table['with_stopwords'] = [False]*without_stopwords_table.shape[0]\n",
    "without_stopwords_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([with_stopwords_table, without_stopwords_table])\n",
    "\n",
    "accuracy_graph = all_results.groupby('with_stopwords')['accuracy'].mean().plot.bar()\n",
    "accuracy_graph.bar_label(accuracy_graph.containers[0])\n",
    "plt.title('% Accuracy With and Without Stopwords')\n",
    "plt.ylabel('% Accurate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2513f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_graph = all_results.groupby('with_stopwords')['time_elapsed'].mean().plot.bar()\n",
    "time_graph.bar_label(time_graph.containers[0])\n",
    "plt.title('Runtime With and Without Stopwords')\n",
    "plt.ylabel('Time in Seconds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 0\n",
    "begin = 0\n",
    "\n",
    "total_num_emails = df.shape[0]\n",
    "\n",
    "results = {\n",
    "           'email_#': list(range(1,total_num_emails+1)),\n",
    "           'actual_classification': df[PREDICTION].values.tolist(),\n",
    "           'predicted_classification': [],\n",
    "           'result': []\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 2 for \"Email No.\" and \"Prediction\" columns\n",
    "total_vocab = len(df.columns) - 2\n",
    "\n",
    "partition_size = total_num_emails//5\n",
    "\n",
    "for i in range(1,6):\n",
    "    start_time = time.time()\n",
    "    end += partition_size\n",
    "\n",
    "    if i == 1:\n",
    "        testing_data = df.iloc[begin:end].copy()\n",
    "        training_data = df.iloc[end:]\n",
    "    elif i == 5:\n",
    "        testing_data = df.iloc[begin:].copy()\n",
    "        training_data = df.iloc[:begin]\n",
    "    else:\n",
    "        testing_data = df.iloc[begin:end].copy()\n",
    "        training_data_sections = []\n",
    "        training_data_sections.append(df.iloc[:begin])\n",
    "        training_data_sections.append(df.iloc[end:])\n",
    "        training_data = pd.concat(training_data_sections)\n",
    "\n",
    "    begin += partition_size\n",
    "\n",
    "    spam_proportion = training_data[PREDICTION].value_counts()[1] / training_data.shape[0]\n",
    "    ham_proportion = training_data[PREDICTION].value_counts()[0] / training_data.shape[0]\n",
    "\n",
    "    spam_training_emails = training_data.loc[training_data[PREDICTION] == 1]\n",
    "    total_spam_words = count_vocab(spam_training_emails)\n",
    "\n",
    "    ham_training_emails = training_data.loc[training_data[PREDICTION] == 0]\n",
    "    total_ham_words = count_vocab(ham_training_emails)\n",
    "\n",
    "    word_spamicities = build_word_spamicity_dict(spam_training_emails, total_vocab, total_spam_words)\n",
    "    word_hamicities = build_word_spamicity_dict(ham_training_emails, total_vocab, total_ham_words)\n",
    "\n",
    "    i = 0\n",
    "    for index, email in testing_data.iterrows():\n",
    "        email_result = calculate_email(email, word_spamicities, word_hamicities, spam_proportion, ham_proportion, testing_data)\n",
    "        results['predicted_classification'].append(email_result)\n",
    "        \n",
    "        if results['actual_classification'][i] and results['predicted_classification']:\n",
    "            results['result'].append('TP')\n",
    "        elif not results['actual_classification'] and not results['predicted_classification']:\n",
    "            results['result'].append('TN')\n",
    "        elif results['actual_classification'] and not results['predicted_classification']:\n",
    "            results['result'].append('FN')\n",
    "        else:\n",
    "            results['result'].append('FP')\n",
    "        i += 1\n",
    "        \n",
    "confusion_matrix = pd.DataFrame(data=results)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e254a",
   "metadata": {},
   "source": [
    "## Step 2: Get probabilities that any one email in the training data is either spam or ham\n",
    "\n",
    "In the labelled dataset, count the number of spam and ham emails.\n",
    "\n",
    "$P(Spam) = \\frac{Spam\\,Emails}{Total\\,Emails}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bca9ca",
   "metadata": {},
   "source": [
    "$P(Ham) = \\frac{Ham\\,Emails}{Total\\,Emails}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e43c9",
   "metadata": {},
   "source": [
    "## Step 3: Get the \"spamicity\" and \"hamicity\" probability of each word in the testing data email\n",
    "\n",
    "**w** = word\n",
    "<br>**vocab** = total words in dataset\n",
    "<br>**spam_vocab**\n",
    "<br>**wi_spam_count**\n",
    "\n",
    "Count all unique words in the labelled dataset to get **vocab**.\n",
    "\n",
    "Count the total number of words in labelled spam emails (ignoring uniqueness) to get **spam_vocab**.\n",
    "\n",
    "For each word **w**, count all instances of the word in the spam emails to get **wi_spam_count**.\n",
    "\n",
    "Calculate spamicity of each word and store the word and its spamicity in a dictionary\n",
    "\n",
    "$P(w_{i}|Spam) = \\frac{wi\\_spam\\_count\\,+\\,\\alpha}{spam\\_vocab\\,+\\,\\alpha \\cdot vocab}$\n",
    "\n",
    "$\\alpha$ is a coefficient that prevents a probability from being 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba26950",
   "metadata": {},
   "source": [
    "## Step 4: Calculate the \"spamicity\" and \"hamicity\" of each email\n",
    "\n",
    "Multiply spamicities of each word together to get $\\prod_{i=1}^{n}P(w_{i}|Spam)$.\n",
    "\n",
    "Multiply that product by the probability that any email is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98189d84",
   "metadata": {},
   "source": [
    "## Step 5: Compare hamicity and spamicity scores to classify emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728084db",
   "metadata": {},
   "source": [
    "## Step 6: Check accuracy of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
