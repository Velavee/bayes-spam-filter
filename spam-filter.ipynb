{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed19cfc7",
   "metadata": {},
   "source": [
    "# Bayes Theorem for Predicting the Probability of an Email Being Spam\n",
    "\n",
    "S = Spam\n",
    "w = Word\n",
    "\n",
    "$P(Spam|w_{1}, w_{2},..., w_{n}) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_{i}|Spam)$\n",
    "\n",
    "The probability that an email consisting of the words $w_{1}, w_{2},... w_{n}$ is proportional to the probability that any given email is spam multiplied by the product of each word's probability to appear in a spam email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68506f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "PREDICTION = 'Prediction'\n",
    "CLASSIFICATION = 'Classiciation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c127b8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81159678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocab(emails):\n",
    "    total_words = 0\n",
    "    \n",
    "    for index, row in emails.iterrows():\n",
    "        total_words += sum(row.values[1:-2])\n",
    "            \n",
    "    return total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8521603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_spamicity(w_spam_count, vocab, spam_vocab):\n",
    "    alpha = 1\n",
    "    \n",
    "    spamicity = (w_spam_count + alpha) / (spam_vocab + alpha * vocab)\n",
    "    return spamicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2558e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_spamicity_dict(spam_emails, vocab, spam_vocab):\n",
    "    spam_word_appearances = {}\n",
    "    \n",
    "    for (column_name, column_data) in spam_emails.iteritems():\n",
    "        if column_name != 'Email No.' and column_name != PREDICTION and column_name != CLASSIFICATION:\n",
    "            spam_word_appearances[column_name] = sum(column_data.values)\n",
    "            \n",
    "    for word in spam_word_appearances:\n",
    "        spam_word_appearances[word] = calculate_word_spamicity(spam_word_appearances[word], vocab, spam_vocab)\n",
    "            \n",
    "    return spam_word_appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0da3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_email(email, word_spamicities, word_hamicities, spam_proportion, ham_proportion):\n",
    "    email_spamicity = math.log(spam_proportion)\n",
    "    email_hamicity = math.log(ham_proportion)\n",
    "    \n",
    "    for column in testing_data.columns[1:-2]:\n",
    "        if email[column] > 0:\n",
    "            email_spamicity += math.log(word_spamicities[column])*email[column]\n",
    "            email_hamicity += math.log(word_hamicities[column])*email[column]\n",
    "            \n",
    "    return 1 if email_spamicity >= email_hamicity else 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27112486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(testing_emails):\n",
    "    number_correct = 0\n",
    "    for index, email in testing_emails.iterrows():\n",
    "        if email[PREDICTION] == email[CLASSIFICATION]:\n",
    "            number_correct += 1\n",
    "        \n",
    "    return number_correct / testing_data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83be745",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42190751",
   "metadata": {},
   "source": [
    "## Step 1: Partition the data into training and test segments\n",
    "\n",
    "20% of the data for testing, and the remaining 80% is training (i.e. the 80% training data will confirm whether the 20% testing data labels are correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9645163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # Emails:5172\n",
      "Total Vocab: 2866\n",
      "\n",
      "Begin: Email 1\n",
      "End: Email 1034\n",
      "% of spam emails: 0.291445142580957\n",
      "% of ham emails: 0.708554857419043\n",
      "total spam words: 987979\n",
      "total ham words: 1754023\n",
      "Accuracy: 93.23017408123792%\n",
      "\n",
      "Begin: Email 1035\n",
      "End: Email 2068\n",
      "% of spam emails: 0.29337844369260513\n",
      "% of ham emails: 0.7066215563073949\n",
      "total spam words: 1018299\n",
      "total ham words: 1808522\n",
      "Accuracy: 96.5183752417795%\n",
      "\n",
      "Begin: Email 2069\n",
      "End: Email 3102\n",
      "% of spam emails: 0.291686805219913\n",
      "% of ham emails: 0.708313194780087\n",
      "total spam words: 1099899\n",
      "total ham words: 1871004\n",
      "Accuracy: 95.16441005802709%\n",
      "\n",
      "Begin: Email 3103\n",
      "End: Email 4136\n",
      "% of spam emails: 0.28709521507974867\n",
      "% of ham emails: 0.7129047849202513\n",
      "total spam words: 990528\n",
      "total ham words: 1894500\n",
      "Accuracy: 93.42359767891682%\n",
      "\n",
      "Begin: Email 4137\n",
      "End: Email 5172\n",
      "% of spam emails: 0.28650870406189555\n",
      "% of ham emails: 0.7134912959381045\n",
      "total spam words: 991291\n",
      "total ham words: 1717739\n",
      "Accuracy: 90.44401544401545%\n",
      "\n",
      "Average Accuracy: 93.75611450079536%\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "# Take out all stopwords\n",
    "for col in df.columns:\n",
    "    if col in stop_words:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "total_num_emails = df.shape[0]\n",
    "print(f'Total # Emails:{total_num_emails}')\n",
    "\n",
    "# Subtract 2 for \"Email No.\" and \"Prediction\" columns\n",
    "total_vocab = len(df.columns) - 2\n",
    "print(f'Total Vocab: {total_vocab}')\n",
    "\n",
    "partition_size = total_num_emails//5\n",
    "\n",
    "end = 0\n",
    "begin = 0\n",
    "score_total = 0\n",
    "        \n",
    "\n",
    "for i in range(1,6):\n",
    "    end += partition_size\n",
    "    \n",
    "    if i == 5:\n",
    "        testing_data = df.iloc[begin:].copy()\n",
    "    else:\n",
    "        testing_data = df.iloc[begin:end].copy()\n",
    "\n",
    "    # This is where the model's prediction will be stored\n",
    "    testing_data[CLASSIFICATION] = \"\"\n",
    "    \n",
    "    if i == 1:\n",
    "        training_data = df.iloc[end:]\n",
    "    elif i == 5:\n",
    "        training_data = df.iloc[:begin]\n",
    "    else:\n",
    "        training_data_sections = []\n",
    "        training_data_sections.append(df.iloc[:begin])\n",
    "        training_data_sections.append(df.iloc[end:])\n",
    "        training_data = pd.concat(training_data_sections)\n",
    "    \n",
    "    begin += partition_size\n",
    "    print(f'\\nBegin: {testing_data.at[testing_data.index[0],\"Email No.\"]}')\n",
    "    print(f'End: {testing_data.at[testing_data.index[-1],\"Email No.\"]}')\n",
    "    \n",
    "    spam_proportion = training_data['Prediction'].value_counts()[1] / training_data.shape[0]\n",
    "    print(f'% of spam emails: {spam_proportion}')\n",
    "    \n",
    "    ham_proportion = training_data['Prediction'].value_counts()[0] / training_data.shape[0]\n",
    "    print(f'% of ham emails: {ham_proportion}')\n",
    "    \n",
    "    spam_training_emails = training_data.loc[training_data[PREDICTION] == 1]\n",
    "\n",
    "    total_spam_words = count_vocab(spam_training_emails)\n",
    "    print(f'total spam words: {total_spam_words}')\n",
    "    \n",
    "    ham_training_emails = training_data.loc[training_data[PREDICTION] == 0]\n",
    "\n",
    "    total_ham_words = count_vocab(ham_training_emails)\n",
    "    print(f'total ham words: {total_ham_words}')\n",
    "    \n",
    "    word_spamicities = build_word_spamicity_dict(spam_training_emails, total_vocab, total_spam_words)\n",
    "    word_hamicities = build_word_spamicity_dict(ham_training_emails, total_vocab, total_ham_words)\n",
    "    \n",
    "    i = 0\n",
    "    for index, email in testing_data.iterrows():\n",
    "        testing_data[CLASSIFICATION].loc[testing_data.index[i]] = calculate_email(email, word_spamicities, word_hamicities, spam_proportion, ham_proportion)\n",
    "        i += 1\n",
    "\n",
    "    score = calculate_accuracy(testing_data)\n",
    "    print(f'Accuracy: {score}%')\n",
    "    score_total += score\n",
    "    \n",
    "print(f'\\nAverage Accuracy: {score_total/5}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e254a",
   "metadata": {},
   "source": [
    "## Step 2: Get probabilities that any one email in the training data is either spam or ham\n",
    "\n",
    "In the labelled dataset, count the number of spam and ham emails.\n",
    "\n",
    "$P(Spam) = \\frac{Spam\\,Emails}{Total\\,Emails}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    spam_proportion = training_data['Prediction'].value_counts()[1] / training_data.shape[0]\n",
    "    spam_proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bca9ca",
   "metadata": {},
   "source": [
    "$P(Ham) = \\frac{Ham\\,Emails}{Total\\,Emails}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ham_proportion = training_data['Prediction'].value_counts()[0] / training_data.shape[0]\n",
    "    ham_proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e43c9",
   "metadata": {},
   "source": [
    "## Step 3: Get the \"spamicity\" and \"hamicity\" probability of each word in the testing data email\n",
    "\n",
    "**w** = word\n",
    "<br>**vocab** = total words in dataset\n",
    "<br>**spam_vocab**\n",
    "<br>**wi_spam_count**\n",
    "\n",
    "Count all unique words in the labelled dataset to get **vocab**.\n",
    "\n",
    "Count the total number of words in labelled spam emails (ignoring uniqueness) to get **spam_vocab**.\n",
    "\n",
    "For each word **w**, count all instances of the word in the spam emails to get **wi_spam_count**.\n",
    "\n",
    "Calculate spamicity of each word and store the word and its spamicity in a dictionary\n",
    "\n",
    "$P(w_{i}|Spam) = \\frac{wi\\_spam\\_count\\,+\\,\\alpha}{spam\\_vocab\\,+\\,\\alpha \\cdot vocab}$\n",
    "\n",
    "$\\alpha$ is a coefficient that prevents a probability from being 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Subtract 2 for \"Email No.\" and \"Prediction\" columns\n",
    "    total_vocab = len(training_data.columns) - 2\n",
    "    total_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "    spam_training_emails = training_data.loc[training_data[PREDICTION] == 1]\n",
    "\n",
    "    total_spam_words = count_vocab(spam_training_emails)\n",
    "    total_spam_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f38a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ham_training_emails = training_data.loc[training_data[PREDICTION] == 0]\n",
    "\n",
    "    total_ham_words = count_vocab(ham_training_emails)\n",
    "    total_ham_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    word_spamicities = build_word_spamicity_dict(spam_training_emails, total_vocab, total_spam_words)\n",
    "    word_spamicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "    word_hamicities = build_word_spamicity_dict(ham_training_emails, total_vocab, total_ham_words)\n",
    "    word_hamicities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba26950",
   "metadata": {},
   "source": [
    "## Step 4: Calculate the \"spamicity\" and \"hamicity\" of each email\n",
    "\n",
    "Multiply spamicities of each word together to get $\\prod_{i=1}^{n}P(w_{i}|Spam)$.\n",
    "\n",
    "Multiply that product by the probability that any email is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_data_spam_map = calculate_emails(testing_data, word_spamicities, spam_proportion)\n",
    "    test_data_spam_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_data_ham_map = calculate_emails(testing_data, word_hamicities, ham_proportion)\n",
    "    test_data_ham_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98189d84",
   "metadata": {},
   "source": [
    "## Step 5: Compare hamicity and spamicity scores to classify emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afe75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for key in test_data_spam_map:\n",
    "        if test_data_spam_map[key] >= test_data_ham_map[key]:\n",
    "            testing_data[CLASSIFICATION].loc[testing_data.index[key]] = 1\n",
    "        else:\n",
    "            testing_data[CLASSIFICATION].loc[testing_data.index[key]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728084db",
   "metadata": {},
   "source": [
    "## Step 6: Check accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    score = calculate_accuracy(testing_data)\n",
    "    f'Accuracy: {score}%'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
